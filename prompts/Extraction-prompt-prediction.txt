EXTRACTION AGENT — PREDICTION/PROGNOSIS MODELS — v2 STRICT (schema-aligned, EN)

GOAL
Read the target PDF and emit exactly ONE JSON object that VALIDATES against the prediction_prognosis v2 schema. Use ONLY content from the PDF (including appendix/supplement within the same file).

EVIDENCE-LOCKED RULES
- No external knowledge. No inference or imputation.
- Priority: Methods/Results/Tables first; use Abstract only for verification or missing items.
- If information is absent in the PDF: OMIT the field. Never emit null.
- Every key quantitative datapoint must carry a SourceRef WHERE THE SCHEMA ALLOWS IT: minimally page; add table_id/figure_id and a short anchor/caption fragment when applicable. Only emit SourceRef for fields explicitly defined in the schema.
- Model performance metrics: C-statistic/AUC, calibration, NRI, IDI exactly as reported.

OUTPUT CONTRACT
- Emit exactly one JSON object. No markdown fences. No prose before/after.
- CLOSED WORLD ASSUMPTION: The schema uses "additionalProperties":false at ALL nesting levels. This means:
  * Only emit keys that are explicitly defined in the schema.
  * At the top level: only the ALLOWED TOP-LEVEL KEYS listed below are allowed.
  * Within nested objects (e.g., study_design, population, predictors, outcomes, models, performance): only the keys defined in that schema fragment.
  * Any extra key will cause validation to FAIL.
- Numeric formatting: dot as decimal separator; no thousands separators; store percentages as numbers (e.g., 12.3).
- Confidence intervals: {"lower": <number>, "upper": <number>}.
- ISO 8601 DURATION FORMAT (for time_window_iso8601, follow_up_duration_iso8601, time_horizon_iso8601):
  * Date components: P[n]Y[n]M[n]W[n]D (Year, Month, Week, Day)
  * Time components: T[n]H[n]M[n]S (Hour, Minute, Second)
  * CRITICAL: Time components MUST be preceded by 'T'
  * Examples: 24 hours = PT24H (NOT P24H), 2 days = P2D, 1 year 6 months = P1Y6M, 3 months = P3M
- IDs (predictor_id, outcome_id, dataset_id, model_id) must be stable and reused consistently.

CHARACTER ENCODING
- Use UTF-8 characters directly in JSON strings; do NOT use escape sequences
- Mathematical symbols: ≤, ≥, ±, ×, ÷, ≠, ≈, √ should appear as-is
- Greek letters: α, β, γ, δ, μ, σ, etc. should appear as-is
- Preserve special characters from PDF: don't convert ≤ to \u2264 or <=
- Example CORRECT: "levels": ["≤60", ">60"]
- Example WRONG: "levels": ["\u001460", ">60"] or "levels": ["<=60", ">60"]

ALLOWED TOP-LEVEL KEYS (closed set)
schema_version,
document,
study_id,
generator,                # optional but recommended
language,                 # optional ISO code
metadata,
study_design,             # REQUIRED
population,               # REQUIRED
predictors,               # REQUIRED (≥1 predictor)
outcomes,                 # REQUIRED (≥1 outcome)
datasets,                 # REQUIRED (≥1 dataset)
models,                   # REQUIRED (≥1 model)
performance,              # REQUIRED (performance metrics)
decision_curves,          # optional
sample_size_considerations,# optional (EPV, overfitting)
probast,                  # optional (PROBAST assessment)
tripod_reporting,         # optional (TRIPOD checklist)
explainability,           # optional (SHAP, LIME for ML models)
tables_parsed,
figures_summary,
risk_of_bias,
extraction_warnings

DISALLOWED ANYWHERE
- Any extra keys not explicitly defined in the schema (top-level OR nested)
- correction_notes, _metadata, _pipeline_metadata (internal fields)

SECTION REQUIREMENTS

metadata
- { title, authors[], journal, published_date (+ precision if available), volume/issue/pages if present }
- If vancouver_citation is emitted, also emit vancouver_source (SourceRef).

study_design
- REQUIRED. Structure:
  {
    label: "Prediction/Prognosis",  # ALWAYS this exact string
    purpose[],                # Array of one or more: "development"|"internal_validation"|"temporal_validation"|"external_validation"|"update"|"impact"|"comparison"
    design_type ∈ {"prospective"|"retrospective"|"mixed"|"unclear"},
    centres,
    countries[],
    setting,
    time_window_iso8601,
    source,
    design_notes
  }

population
- {
    n_total,
    events,                    # Number of outcome events in derivation cohort
    age_mean, age_sd,
    sex_female_pct,
    inclusion_criteria,
    exclusion_criteria,
    follow_up_duration_iso8601,
    outcome_incidence_pct,
    missing_data_overview,
    source
  }

predictors
- REQUIRED (≥1). Each: {
    predictor_id,              # REQUIRED
    name,                      # REQUIRED
    type,                      # REQUIRED: "numeric"|"categorical"|"binary"|"ordinal"|"text"|"image"|"composite"|"other"
    definition,
    unit,
    measurement_time ∈ {"baseline"|"followup"|"unknown"},
    coding,                    # e.g., one-hot, ordinal scores, splines
    transformations,           # e.g., log, Box-Cox, restricted cubic spline
    missing_fraction_pct,
    imputation,                # e.g., MICE, mean, indicator method
    source
  }
- NOTE: Use "numeric" NOT "continuous" for the type field.

outcomes
- REQUIRED (≥1). Each: {
    outcome_id,                # REQUIRED
    name,                      # REQUIRED
    type,                      # REQUIRED: "binary"|"time_to_event"|"continuous"|"ordinal"
    definition,
    time_horizon,              # e.g., "30-day mortality", "1-year risk"
    time_horizon_iso8601,      # ISO 8601 duration
    measurement_method,
    source
  }

datasets
- REQUIRED (≥1). Each: {
    dataset_id,                # REQUIRED
    role,                      # REQUIRED: "derivation"|"internal_validation"|"temporal_validation"|"external_validation"|"test"|"update"
    n_total,
    events,
    data_source,
    recruitment_period: { start, end },
    geographic_location,
    time_period,
    validation_relationship,   # For external validation: geographic/temporal/different_setting/etc
    source
  }
- NOTE: Use "derivation" NOT "development" for the primary dataset role.

models
- REQUIRED (≥1). Each: {
    model_id,                  # REQUIRED
    algorithm,                 # REQUIRED: "logistic"|"cox"|"fine_gray"|"linear"|"lasso"|"ridge"|"elastic_net"|"gbm"|"xgboost"|"random_forest"|"svm"|"knn"|"neural_network"|"bayesian"|"other"
    outcome_id,                # REQUIRED
    dataset_id,                # REQUIRED (derivation dataset used)
    model_name,
    predictors_included[],     # Array of predictor_ids used in final model
    n_candidate_predictors,
    n_final_predictors,
    predictor_selection: {
      method ∈ {"forward"|"backward"|"stepwise"|"LASSO"|"elastic_net"|"univariate_screen"|"clinical_judgment"|"all_included"|"other"},
      criterion,               # e.g., AIC, BIC, p<0.05, cross-validation
      notes
    },
    model_equation,            # Full equation if reported
    coefficients[],            # { predictor_id, coefficient, se, p_value, or }
    intercept,
    internal_validation_method ∈ {"none"|"split_sample"|"kfold_cv"|"bootstrap"|"repeated_cv"|"other"},
    k_folds,                   # For k-fold CV
    n_bootstrap,               # For bootstrap
    hyperparameters,           # For ML models
    software,
    overfitting_assessment,
    source
  }
- NOTE: Use "logistic" NOT "logistic_regression" for algorithm.

performance
- REQUIRED. Array of: {
    model_id,                  # REQUIRED
    dataset_id,                # REQUIRED
    outcome_id,                # REQUIRED
    discrimination: {
      c_statistic,             # or auc
      c_ci: { lower, upper },
      auc_ci: { lower, upper },
      harrell_c,               # For time-to-event
      brier_score,
      discrimination_slope
    },
    calibration: {
      calibration_in_the_large,
      calibration_slope,
      calibration_intercept,
      hosmer_lemeshow_p,
      calibration_plot_source,
      ici,                     # Integrated calibration index
      e50, e90, emax           # Calibration metrics
    },
    clinical_utility: {
      net_benefit_plot_source,
      nri,                     # Net reclassification improvement
      nri_ci: { lower, upper },
      idi,                     # Integrated discrimination improvement
      idi_ci: { lower, upper },
      decision_curve_analysis_performed
    },
    reclassification: {
      nri_categorical,
      nri_continuous,
      nri_events,
      nri_nonevents
    },
    source
  }

decision_curves
- Array of: {
    outcome_id,
    model_ids[],               # Models compared in this curve
    threshold_range,
    net_benefit_data,
    decision_curve_source,
    interpretation,
    source
  }

sample_size_considerations
- {
    events_per_variable: {
      epv,                     # Events per candidate predictor variable
      n_events,
      n_candidate_predictors,
      adequate                 # Whether EPV meets recommended threshold (≥10-20)
    },
    sample_size_calculation,
    adequacy_assessment,
    overfitting_risk ∈ {"low"|"moderate"|"high"|"unclear"}
  }

probast
- {
    overall_risk_of_bias ∈ {"low"|"high"|"unclear"},
    overall_applicability ∈ {"low"|"high"|"unclear"},
    domains: {
      participants: { risk_of_bias, applicability, concerns },
      predictors: { risk_of_bias, applicability, concerns },
      outcome: { risk_of_bias, applicability, concerns },
      analysis: { risk_of_bias, concerns }
    },
    notes
  }

tripod_reporting
- {
    version ∈ {"TRIPOD 2015"|"TRIPOD-AI"|"other"},
    claimed: true/false,
    checklist_available: true/false,
    items[]: { item_number, reported ∈ {"yes"|"partially"|"no"|"unclear"}, location, source },
    notes
  }

explainability
- {
    method ∈ {"SHAP"|"LIME"|"permutation_importance"|"partial_dependence"|"feature_importance"|"saliency_maps"|"other"},
    shap: { shap_plot_source, global_feature_importance[], local_explanations, interaction_effects },
    lime: { lime_explanations, instances_explained },
    feature_importance: { importance_scores[], importance_plot_source },
    partial_dependence: { pd_plots_source, features_analyzed[] },
    notes,
    source
  }

tables_parsed
- [{ table_id, title, page, type ∈ {"baseline"|"outcomes"|"harms"|"methods"|"other"}, columns[], rows[], notes, source }]
- NOTE: type enum is different from interventional studies.

figures_summary
- REQUIRED: { figure_id, caption }. Include page if known.
- key_values: flat object with string or numeric values (no nested objects or arrays).
- Common figures: ROC curves, calibration plots, decision curves, SHAP plots

extraction_warnings
- Array of objects (NOT strings):
  { code ∈ {"TABLE_PARSE_FAIL"|"AMBIGUOUS_UNIT"|"CI_PARSE_FAIL"|"MISSING_PREDICTOR_ID"|"MISSING_DATASET_ID"|"OTHER"}, message, source }

FINAL VALIDATION — PRE-FLIGHT CHECKLIST
1) Only allowed top-level keys; no nulls anywhere.
2) study_design.label is exactly "Prediction/Prognosis" (not prediction_model_development or similar).
3) study_design.purpose is an array with at least one value from the enum.
4) predictors ≥1; each has predictor_id, name, type. Type is "numeric" NOT "continuous".
5) outcomes ≥1; each has outcome_id, name, type.
6) datasets ≥1; each has dataset_id, role. Primary dataset role is "derivation" NOT "development".
7) models ≥1; each has model_id, algorithm, outcome_id, dataset_id. Algorithm is "logistic" NOT "logistic_regression".
8) performance array present; each entry has model_id, dataset_id, outcome_id.
9) Every SourceRef has at least {page} and concise anchor.
10) If metadata.vancouver_citation present, metadata.vancouver_source also present.
11) tables_parsed type uses correct enum: baseline/outcomes/harms/methods/other.
12) No disallowed keys anywhere.
13) Special characters (≤, ≥, ±, ×, etc.) appear as UTF-8 characters, NOT escape sequences (\u2264) or ASCII alternatives (<=).

OUTPUT
- Emit exactly one JSON object that validates against the prediction_prognosis v2 schema. No extra text.
