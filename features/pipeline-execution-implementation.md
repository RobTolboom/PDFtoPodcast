# Feature: Pipeline Execution Implementation

**Status:** Planning
**Aangemaakt:** 2025-10-14
**Eigenaar:** Rob Tolboom
**Branch:** feature/pipeline-execution-implementation

---

## ğŸ“‹ Doel

Implementeer een volledig functionele **Execution Screen** voor de Streamlit web interface die de bestaande CLI pipeline (`run_four_step_pipeline()`) integreert met een gebruiksvriendelijke, real-time progress tracking UI. Dit maakt de volledige PDF â†’ Extraction workflow beschikbaar via de web interface, zonder de gebruiker naar de command-line te verwijzen.

---

## ğŸ¯ Scope

### In Scope

**Core Functionaliteit:**
- Nieuwe `src/streamlit_app/screens/execution.py` module
- Integration met bestaande `src.pipeline.orchestrator.run_four_step_pipeline()`
- Real-time progress tracking per pipeline stap
- Intelligent error handling met kritische vs. non-kritische fouten
- Verbose logging toggle (instelbaar via Settings screen)
- Navigatie terug naar Settings screen na completion (success of failure)

**UI Components:**
- Expandable status containers per pipeline stap (`st.status()`)
- Progress indicators met timestamps
- Error display met duidelijke foutmeldingen
- Step completion indicators (âœ… / âŒ)
- Optionele verbose logs (API calls, token usage, timing)

**Error Handling Strategy:**
- **Critical errors** (stop pipeline):
  - Classification failure â†’ geen publication type â†’ stop
  - Extraction failure â†’ geen data voor validation â†’ stop
  - LLM API errors (rate limits, authentication, network)
- **Non-critical errors** (log maar continue):
  - Validation warning (quality score laag maar niet fatal)
  - Schema compatibility warnings
- **Expected flow** (geen error):
  - Validation passed â†’ skip correction
  - Correction niet nodig â†’ normale flow

### Out of Scope

- **Results screen** - Bestaande JSON viewing in Settings screen is voldoende
- **Cancel/Stop functionaliteit** - Gebruiker hoeft niet te kunnen annuleren
- **Background/Async execution** - Pipeline is blocking (user wacht)
- **Progress percentage** - Alleen "Running" / "Completed" / "Failed" per stap
- **Cost estimation** - API kosten tracking niet in deze feature
- **Retry mechanisme** - Bij error: gebruiker moet handmatig opnieuw proberen via Settings

---

## ğŸ“Š Huidige Situatie

### âœ… Wat werkt al

**Streamlit Interface (3 van 5 screens geÃ¯mplementeerd):**
1. **Intro Screen** (`intro.py`) - Welkomstscherm met feature overview
2. **Upload Screen** (`upload.py`) - PDF upload met duplicate detection en file selection
3. **Settings Screen** (`settings.py`) - Pipeline configuratie:
   - Step selection (classification, extraction, validation, correction)
   - LLM provider selectie (OpenAI / Claude)
   - Max pages configuratie
   - Advanced settings (breakpoints, verbose logging, cleanup policy)
   - JSON result viewing/deletion voor bestaande outputs

**Pipeline Orchestration (volledig functioneel in CLI):**
- `run_pipeline.py` - CLI entry point met argumenten
- `src/pipeline/orchestrator.py` - `run_four_step_pipeline()` function:
  - Step 1: Classification (identify publication type)
  - Step 2: Extraction (schema-based data extraction)
  - Step 3: Validation (dual: schema + optional LLM semantic)
  - Step 4: Correction (conditional, only if validation fails)
- `src/pipeline/file_manager.py` - File management (filename-based outputs in `tmp/`)
- `src/pipeline/validation_runner.py` - Dual validation logic
- `src/llm/` - Multi-provider LLM abstraction (OpenAI, Claude)

**Session State Management:**
- `src/streamlit_app/session_state.py` - Initialized settings:
  ```python
  st.session_state.settings = {
      "llm_provider": "openai",
      "max_pages": None,
      "steps_to_run": ["classification", "extraction", "validation", "correction"],
      "cleanup_policy": "keep_forever",
      "breakpoint": None,
      "verbose_logging": False,
  }
  ```

### âŒ Wat ontbreekt

**Execution Screen (`execution.py`):**
- Placeholder in `app.py` lijn 78-79:
  ```python
  elif st.session_state.current_phase == "execution":
      st.info("ğŸ”„ Execution phase - coming in Phase 4")
  ```
- Geen import in `src/streamlit_app/screens/__init__.py`
- Geen routing naar daadwerkelijke pipeline execution

**Results Screen (`results.py`):**
- Out of scope - bestaande JSON viewing functionaliteit in Settings screen is voldoende

---

## ğŸ—ï¸ Implementatie Strategie

### Architectuur Beslissing: Enhanced Implementation (Optie B)

**Gekozen aanpak:**
- **Real-time progress** met Streamlit native components
- **Blocking execution** (geen async/threading complexity)
- **Wrapper functions** rond bestaande orchestrator logica
- **Intelligent error handling** met kritische vs. non-kritische fouten

**Waarom niet Minimaal (Optie A)?**
- Te basic: geen feedback tijdens 2-5 minuten wachttijd
- Slechte UX: gebruiker weet niet wat er gebeurt

**Waarom niet Async (Optie C)?**
- Te complex: threading in Streamlit is tricky
- Niet nodig: gebruiker wil niet annuleren
- Overkill voor MVP

### Pipeline Wrapper Strategie

**Originele orchestrator** (`src/pipeline/orchestrator.py`):
```python
def run_four_step_pipeline(
    pdf_path: Path,
    max_pages: int | None,
    llm_provider: str,
    breakpoint_after_step: str | None,
    have_llm_support: bool
) -> dict[str, Any]:
    # Returns: {"classification": {...}, "extraction": {...}, ...}
```

**Streamlit wrapper** (nieuwe functie in `execution.py`):
```python
def run_pipeline_with_progress(
    pdf_path: Path,
    settings: dict,
    verbose: bool
) -> dict[str, Any]:
    """
    Wraps run_four_step_pipeline() met Streamlit progress UI.

    Voor elke stap:
    1. Open st.status() expandable container
    2. Roep pipeline step functie aan
    3. Update status (success/failure)
    4. Log verbose details (indien enabled)
    5. Handle errors (stop of continue)
    """
```

**Alternative: Refactor orchestrator**
- âŒ **Niet gekozen**: te invasive, breekt CLI interface
- âœ… **Gekozen**: wrapper approach, hergebruik bestaande code

---

## ğŸ“ UI Design Specificatie

### Layout Structure

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ## ğŸš€ Pipeline Execution                                  â•‘
â•‘  Processing: sample_paper.pdf                              â•‘
â•‘  Settings: OpenAI, All pages, Steps: 1,2,3,4               â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘                                                             â•‘
â•‘  âœ… Step 1: Classification                [Completed]      â•‘
â•‘     â””â”€ Publication Type: interventional_trial              â•‘
â•‘     â””â”€ DOI: 10.1186/s12871-025-02345-6                     â•‘
â•‘     â””â”€ Completed in 8.3s                                   â•‘
â•‘     [View Details â–¼]                                        â•‘
â•‘        â€¢ Uploaded PDF to OpenAI GPT-5                      â•‘
â•‘        â€¢ Input tokens: 24,583 | Output: 1,247              â•‘
â•‘        â€¢ Saved: tmp/sample_paper-classification.json       â•‘
â•‘                                                             â•‘
â•‘  ğŸ”„ Step 2: Extraction                   [Running...]      â•‘
â•‘     â””â”€ Using schema: interventional_trial (~8,500 tokens)  â•‘
â•‘     â””â”€ Elapsed: 12.4s                                      â•‘
â•‘                                                             â•‘
â•‘  â³ Step 3: Validation                   [Pending]         â•‘
â•‘                                                             â•‘
â•‘  â³ Step 4: Correction                   [Pending]         â•‘
â•‘                                                             â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â•‘
â•‘  [â¬…ï¸ Back to Settings]                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Step States

| State | Icon | Description | Expandable | Actions |
|-------|------|-------------|-----------|---------|
| **Pending** | â³ | Not yet started | No | None |
| **Running** | ğŸ”„ | Currently executing | Yes, auto-expanded | Show elapsed time |
| **Success** | âœ… | Completed successfully | Yes, collapsed by default | View details, View JSON |
| **Warning** | âš ï¸ | Completed with warnings | Yes, auto-expanded | View warnings, Continue |
| **Failed** | âŒ | Critical error, pipeline stopped | Yes, auto-expanded | View error, Retry |

### Verbose Logging Content

**When `settings["verbose_logging"] = True`:**

Show inside expandable step details:
- LLM provider and model used
- API call timing (start â†’ end)
- Token usage (input + output)
- File paths (saved JSON locations)
- Schema information (name, estimated tokens)
- Validation scores (if applicable)

**When `settings["verbose_logging"] = False`:**

Show only:
- Step name and status
- High-level result (e.g., "Publication Type: interventional_trial")
- Elapsed time
- Error messages (if any)

---

## âœ… Acceptatiecriteria

### Functioneel

1. **Pipeline Execution:**
   - âœ… Execution screen wordt geladen wanneer `current_phase = "execution"`
   - âœ… Pipeline gebruikt settings uit `st.session_state.settings`
   - âœ… Alleen geselecteerde steps worden uitgevoerd (`steps_to_run`)
   - âœ… Pipeline roept `run_four_step_pipeline()` aan met correcte parameters
   - âœ… Results worden opgeslagen in `tmp/` directory met filename-based naming

2. **Progress Tracking:**
   - âœ… Elke step heeft een duidelijke status (Pending/Running/Success/Warning/Failed)
   - âœ… Running step toont elapsed time
   - âœ… Completed steps tonen completion time
   - âœ… Status updates in real-time (geen page refresh nodig)

3. **Error Handling:**
   - âœ… Classification failure â†’ stop pipeline, toon error, enable "Back to Settings"
   - âœ… Extraction failure â†’ stop pipeline, toon error, enable "Back to Settings"
   - âœ… LLM API errors â†’ stop pipeline, toon actionable error message
   - âœ… Validation warnings â†’ log maar continue naar correction (indien selected)
   - âœ… Correction failure â†’ toon error maar mark pipeline als "completed with errors"

4. **Verbose Logging:**
   - âœ… Verbose mode shows: LLM calls, token usage, file paths, timing
   - âœ… Non-verbose mode shows: high-level status, errors, results only
   - âœ… Toggle is configurable via Settings screen (`verbose_logging`)

5. **Navigation:**
   - âœ… "Back to Settings" button altijd beschikbaar (bovenaan of onderaan)
   - âœ… Bij completion: automatic redirect naar Settings screen na 3 seconden (met cancel optie)
   - âœ… Bij critical error: blijf op Execution screen met "Back to Settings" button

### Technisch

6. **Code Kwaliteit:**
   - âœ… Volledige docstrings volgens project standaard (zie `code-documentation-improvement.md`)
   - âœ… Type hints voor alle functie signatures
   - âœ… Error handling met try/except en duidelijke error messages
   - âœ… Logging met `console.print()` voor debugging (in verbose mode)

7. **Integratie:**
   - âœ… Export `show_execution_screen` in `src/streamlit_app/screens/__init__.py`
   - âœ… Import en route in `app.py`
   - âœ… Hergebruik van bestaande `run_four_step_pipeline()` zonder modificaties
   - âœ… Hergebruik van bestaande `PipelineFileManager` voor output files

8. **Testing:**
   - âœ… Handmatige test: upload PDF â†’ configure settings â†’ execute pipeline â†’ verify outputs
   - âœ… Error scenario test: invalid API key â†’ verify error handling
   - âœ… Verbose logging test: enable/disable toggle â†’ verify output detail level
   - âœ… Step selection test: only run classification+extraction â†’ verify validation skipped

### UX

9. **Gebruiksvriendelijkheid:**
   - âœ… Duidelijke feedback tijdens wachttijd (geen "hanging" gevoel)
   - âœ… Expand/collapse voor verbose details (keep UI clean)
   - âœ… Error messages zijn actionable ("Check API key in .env" ipv "Error 401")
   - âœ… Success state toont key results (publication type, DOI, validation status)

10. **Performance:**
    - âœ… UI updates blijven responsive tijdens pipeline execution
    - âœ… Geen significant overhead t.o.v. CLI pipeline (< 1 seconde extra)
    - âœ… File I/O gebeurt via bestaande `PipelineFileManager` (geen duplicaat saves)

---

## ğŸ“‹ Takenlijst

### Fase 1: Setup & Planning âœ…
- [x] Analyseer huidige Streamlit interface structuur
- [x] Analyseer bestaande pipeline orchestrator implementatie
- [x] Definieer implementatie strategie (Enhanced vs Async)
- [x] Schrijf feature document met volledige specificatie
- [x] Maak feature branch: `feature/pipeline-execution-implementation`

### Fase 2: Core Execution Screen Implementation
- [ ] **Create `src/streamlit_app/screens/execution.py`** met:
  - [ ] Module-level docstring met Purpose, Components, Usage Example
  - [ ] `show_execution_screen()` main function
  - [ ] `run_pipeline_with_progress()` wrapper function
  - [ ] Step status tracking helper functions
  - [ ] Error handling logic (critical vs non-critical)
  - [ ] Verbose logging toggle implementation
- [ ] **Update exports in `src/streamlit_app/screens/__init__.py`:**
  - [ ] Add `from .execution import show_execution_screen`
  - [ ] Add `"show_execution_screen"` to `__all__`
- [ ] **Update routing in `app.py`:**
  - [ ] Replace placeholder `st.info()` with `show_execution_screen()` call
  - [ ] Import `show_execution_screen` from screens
- [ ] **Test basic routing:**
  - [ ] Verify execution screen loads when `current_phase = "execution"`
  - [ ] Verify settings are correctly passed from session state

### Fase 3: Pipeline Integration
- [ ] **Implement pipeline wrapper logic:**
  - [ ] Extract settings from `st.session_state.settings`
  - [ ] Map settings to `run_four_step_pipeline()` parameters
  - [ ] Call orchestrator with correct arguments
  - [ ] Capture return value (results dict)
- [ ] **Implement step-by-step execution:**
  - [ ] Wrap Classification step with `st.status()` container
  - [ ] Wrap Extraction step with `st.status()` container
  - [ ] Wrap Validation step with `st.status()` container
  - [ ] Wrap Correction step with `st.status()` container (conditional)
- [ ] **Test step filtering:**
  - [ ] Verify only selected steps run (`steps_to_run`)
  - [ ] Verify unselected steps are skipped
  - [ ] Verify breakpoint handling (if set)

### Fase 4: Progress Tracking & UI
- [ ] **Implement status indicators:**
  - [ ] Pending state (â³) - before execution
  - [ ] Running state (ğŸ”„) - during execution
  - [ ] Success state (âœ…) - after successful completion
  - [ ] Warning state (âš ï¸) - completed with warnings
  - [ ] Failed state (âŒ) - critical error
- [ ] **Implement timing display:**
  - [ ] Elapsed time counter for running step
  - [ ] Completion time for finished steps
  - [ ] Total pipeline duration
- [ ] **Implement result summary:**
  - [ ] Classification: show publication type, DOI
  - [ ] Extraction: show "Completed" + file path
  - [ ] Validation: show overall status, scores
  - [ ] Correction: show "Applied" or "Skipped"

### Fase 5: Verbose Logging Implementation
- [ ] **Create verbose logging helper:**
  - [ ] Function to log API call details (provider, model, tokens)
  - [ ] Function to log file save details (path, size)
  - [ ] Function to log timing details (start, end, duration)
- [ ] **Integrate verbose logging:**
  - [ ] Check `st.session_state.settings["verbose_logging"]`
  - [ ] Show verbose details in expandable sections (when enabled)
  - [ ] Hide verbose details when disabled (clean UI)
- [ ] **Test verbose toggle:**
  - [ ] Enable in Settings â†’ Execute â†’ Verify detailed logs shown
  - [ ] Disable in Settings â†’ Execute â†’ Verify only high-level progress shown

### Fase 6: Error Handling
- [ ] **Implement critical error handling:**
  - [ ] Classification failure â†’ stop, show error, enable "Back"
  - [ ] Extraction failure â†’ stop, show error, enable "Back"
  - [ ] LLM API errors â†’ stop, show actionable message
- [ ] **Implement non-critical error handling:**
  - [ ] Validation warnings â†’ log, continue
  - [ ] Schema compatibility warnings â†’ log, continue
- [ ] **Implement error display:**
  - [ ] Red alert box for critical errors
  - [ ] Yellow warning box for non-critical warnings
  - [ ] Error details in expandable section
  - [ ] Actionable guidance (e.g., "Check .env file")
- [ ] **Test error scenarios:**
  - [ ] Invalid API key â†’ verify error caught and displayed
  - [ ] Network timeout â†’ verify graceful failure
  - [ ] Publication type "overig" â†’ verify pipeline stops correctly

### Fase 7: Navigation & Flow Control
- [ ] **Implement navigation buttons:**
  - [ ] "Back to Settings" button (altijd beschikbaar)
  - [ ] Position button logically (bovenaan of onderaan)
- [ ] **Implement post-completion flow:**
  - [ ] Success: show summary, auto-redirect naar Settings na 3s
  - [ ] Failure: show error, stay on Execution screen with "Back" button
  - [ ] Add countdown timer for auto-redirect ("Redirecting in 3... 2... 1...")
  - [ ] Add "Cancel auto-redirect" option
- [ ] **Test navigation:**
  - [ ] Back button resets to settings phase
  - [ ] Auto-redirect works correctly
  - [ ] Cancel redirect keeps user on Execution screen

### Fase 8: Testing & Validation
- [ ] **Functional testing:**
  - [ ] Test: All 4 steps selected â†’ verify all run
  - [ ] Test: Only classification+extraction â†’ verify validation skipped
  - [ ] Test: Classification fails â†’ verify pipeline stops
  - [ ] Test: Validation passes â†’ verify correction skipped
  - [ ] Test: Validation fails â†’ verify correction runs
- [ ] **Settings integration testing:**
  - [ ] Test: LLM provider = OpenAI â†’ verify OpenAI used
  - [ ] Test: max_pages = 10 â†’ verify only 10 pages processed
  - [ ] Test: verbose_logging = True â†’ verify detailed logs shown
  - [ ] Test: verbose_logging = False â†’ verify clean UI
  - [ ] Test: breakpoint = "classification" â†’ verify pipeline stops after classification
- [ ] **Error handling testing:**
  - [ ] Test: Invalid API key â†’ verify error caught
  - [ ] Test: Network timeout â†’ verify graceful failure
  - [ ] Test: PDF too large â†’ verify error message
  - [ ] Test: Corrupt PDF â†’ verify error handling
- [ ] **UI/UX testing:**
  - [ ] Test: Long running pipeline (> 2 min) â†’ verify UI stays responsive
  - [ ] Test: Expand/collapse details â†’ verify functionality
  - [ ] Test: Auto-redirect countdown â†’ verify cancel works
  - [ ] Test: Back button during execution â†’ verify safe (no corruption)

### Fase 9: Documentation & Finalization
- [ ] **Code documentation:**
  - [ ] Complete docstrings for all functions (Args, Returns, Raises, Example)
  - [ ] Module-level docstring met Purpose, Components, Usage
  - [ ] Inline comments for complex logic
  - [ ] Type hints for all function signatures
- [ ] **Update project documentation:**
  - [ ] Update `CHANGELOG.md` onder "Unreleased"
  - [ ] Update `README.md` indien nodig (execution screen beschrijving)
  - [ ] Update `ARCHITECTURE.md` indien nodig (execution flow diagram)
- [ ] **Code quality checks:**
  - [ ] Run `make format` - Format code with Black
  - [ ] Run `make lint` - Run Ruff linter
  - [ ] Run `make typecheck` - Run mypy type checking
  - [ ] Run `make test-fast` - Run fast unit tests
  - [ ] Fix any warnings or errors
- [ ] **Commit changes:**
  - [ ] Commit: "feat(streamlit): implement execution screen with progress tracking"
  - [ ] Run `make commit` - Pre-commit checks
  - [ ] Verify commit message follows convention

### Fase 10: Integration & Deployment
- [ ] **Integration testing:**
  - [ ] Test complete flow: Intro â†’ Upload â†’ Settings â†’ Execution â†’ Settings
  - [ ] Test with real PDF documents (small, medium, large)
  - [ ] Test with different publication types
  - [ ] Test error recovery (fix API key â†’ retry)
- [ ] **Performance validation:**
  - [ ] Measure execution time vs CLI (should be < 1s overhead)
  - [ ] Verify memory usage (no leaks during long pipelines)
  - [ ] Verify file cleanup (tmp/ directory not growing unnecessarily)
- [ ] **Final checks:**
  - [ ] Run `make ci` - Full CI checks (format, lint, typecheck, tests)
  - [ ] Review code changes (self-review)
  - [ ] Verify no breaking changes to existing screens
  - [ ] Verify no changes to CLI pipeline behavior
- [ ] **Prepare for merge:**
  - [ ] Update feature document with "Completed" status
  - [ ] Push branch naar remote: `git push -u origin feature/pipeline-execution-implementation`
  - [ ] Create Pull Request met template
  - [ ] Request code review

---

## âš ï¸ Risico's

| Risico | Impact | Waarschijnlijkheid | Mitigatie |
|--------|--------|-------------------|-----------|
| **Pipeline blocking hangt Streamlit UI** | Hoog | Medium | Use `st.status()` met updates in try/finally blocks, keep UI responsive |
| **Error tijdens pipeline corrupteert state** | Medium | Medium | Wrap in try/except, reset state on critical errors, safe file I/O |
| **Verbose logging te veel output** | Laag | Hoog | Make expandable by default (collapsed), only expand on error |
| **LLM API timeout tijdens execution** | Medium | Medium | Handle timeout explicitly, show actionable error, don't corrupt tmp/ files |
| **User navigeert weg tijdens execution** | Medium | Laag | Not preventing (no warning), but ensure clean state on return |
| **File permissions error bij write** | Medium | Laag | Check `tmp/` directory writeable on startup, show clear error |
| **Memory leak bij lange pipelines** | Laag | Laag | Reuse existing orchestrator (no new memory patterns), verify with profiling |
| **Inconsistent state tussen Settings en Execution** | Medium | Medium | Always read from `st.session_state.settings`, don't cache locally |

---

## ğŸ”„ Dependencies

### Code Dependencies
- `src.pipeline.orchestrator.run_four_step_pipeline()` - Main pipeline function
- `src.pipeline.file_manager.PipelineFileManager` - File management
- `src.llm.get_llm_provider()` - LLM provider factory
- `st.status()` - Streamlit status containers (requires Streamlit >= 1.28.0)
- `st.session_state.settings` - Pipeline configuration dict

### Environment Dependencies
- `OPENAI_API_KEY` or `ANTHROPIC_API_KEY` - LLM authentication
- Writable `tmp/` directory - For pipeline outputs
- Valid PDF in `uploads/` directory - For processing

### Feature Dependencies
- âœ… Upload screen (already implemented)
- âœ… Settings screen (already implemented)
- âœ… Session state management (already implemented)
- âœ… Pipeline orchestrator (already implemented)
- âŒ Results screen (out of scope - not needed)

---

## ğŸ“ˆ Succes Metrics

### Kwantitatief
- âœ… 100% van geselecteerde steps worden uitgevoerd
- âœ… 0 pipeline state corruption errors
- âœ… < 1 seconde overhead t.o.v. CLI pipeline
- âœ… 100% error scenarios gracefully handled (no crashes)
- âœ… 0 linting/typing errors in new code

### Kwalitatief
- âœ… Gebruiker ziet duidelijke feedback tijdens wachttijd
- âœ… Error messages zijn actionable en begrijpelijk
- âœ… Verbose logging toggle werkt intuÃ¯tief
- âœ… UI blijft responsive tijdens lange pipelines
- âœ… Code is goed gedocumenteerd en begrijpelijk

### User Acceptance
- âœ… Pipeline executie werkt zonder crashes
- âœ… Gebruiker kan succesvol PDF â†’ JSON extraction voltooien via web UI
- âœ… Gebruiker kan errors debuggen via verbose logging
- âœ… Gebruiker kan terug navigeren naar Settings bij problemen

---

## ğŸ”„ Update Log

| Datum | Wijziging | Door |
|-------|-----------|------|
| 2025-10-14 | Feature document aangemaakt met volledige specificatie | Claude Code |
| 2025-10-14 | Implementatie strategie gedefinieerd: Enhanced (Optie B) | Claude Code & Rob Tolboom |
| 2025-10-14 | Error handling strategie uitgewerkt (critical vs non-critical) | Claude Code & Rob Tolboom |
| 2025-10-14 | Verbose logging specificatie toegevoegd (toggle via settings) | Claude Code & Rob Tolboom |
| 2025-10-14 | Results screen verwijderd uit scope (bestaande functionaliteit voldoende) | Claude Code & Rob Tolboom |

---

## ğŸ“š Referenties

### Interne Referenties
- `features/code-documentation-improvement.md` - Documentatie standaard
- `src/pipeline/orchestrator.py` - Bestaande pipeline logica
- `src/streamlit_app/screens/settings.py` - Settings screen implementatie
- `CONTRIBUTING.md` - Development guidelines
- `CLAUDE.md` - Development workflows

### Streamlit Documentation
- [st.status() API](https://docs.streamlit.io/library/api-reference/status/st.status)
- [Session State](https://docs.streamlit.io/library/api-reference/session-state)
- [Progress & Status](https://docs.streamlit.io/library/api-reference/status)

### Design Patterns
- Wrapper Pattern - Wrapping `run_four_step_pipeline()` met UI logic
- Factory Pattern - `get_llm_provider()` voor provider instantiation
- State Machine - Pipeline phases (Pending â†’ Running â†’ Success/Failed)
