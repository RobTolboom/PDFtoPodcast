# PDFtoPodcast Environment Configuration
# Copy this file to .env and fill in your API keys

# ═══════════════════════════════════════════════════════════════════
# LLM PROVIDER CONFIGURATION
# ═══════════════════════════════════════════════════════════════════

# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-5.1
OPENAI_MAX_TOKENS=128000

# OpenAI Reasoning Effort per Pipeline Step (low/medium/high)
# Higher effort = more thinking tokens, better quality, higher cost/latency
REASONING_EFFORT_CLASSIFICATION=low       # Simple task: identify study type
REASONING_EFFORT_EXTRACTION=high          # Complex: PDF analysis, tables, figures
REASONING_EFFORT_VALIDATION=medium        # Semantic validation with medical context
REASONING_EFFORT_CORRECTION=medium        # Understand feedback, improve extraction
REASONING_EFFORT_APPRAISAL=high           # Critical methodology assessment
REASONING_EFFORT_REPORT=medium            # Synthesis with template structure
REASONING_EFFORT_PODCAST=medium           # Creative writing with structure

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_MAX_TOKENS=4096

# ═══════════════════════════════════════════════════════════════════
# GENERAL LLM SETTINGS
# ═══════════════════════════════════════════════════════════════════

LLM_PROVIDER=openai                       # openai or claude
LLM_TEMPERATURE=0.0                       # 0.0 = deterministic
LLM_TIMEOUT=1800                          # 30 minutes for long extractions

# ═══════════════════════════════════════════════════════════════════
# PDF PROCESSING LIMITS
# ═══════════════════════════════════════════════════════════════════

MAX_PDF_PAGES=100                         # Maximum pages to process (API limit)
MAX_PDF_SIZE_MB=32                        # Maximum PDF file size in MB (API limit)
